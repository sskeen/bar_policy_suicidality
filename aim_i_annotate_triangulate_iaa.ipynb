{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4efe4976-f441-4822-90e8-04a11e9bd35b",
      "metadata": {
        "id": "4efe4976-f441-4822-90e8-04a11e9bd35b"
      },
      "source": [
        "# Passive suicidality in a repressive U.S. political context: Aim I\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbcf1a84-27d2-46d1-be12-fef115a5e383",
      "metadata": {
        "id": "cbcf1a84-27d2-46d1-be12-fef115a5e383"
      },
      "source": [
        "_WIP - NOT FOR DISTRIBUTION_\n",
        "\n",
        "_Imports, re-indexes by date, cleans, reduces, restricts by timeframe; permits regex pattern-matched purposive (Wave 1) and random (Wave 2) sampling and named entity redaction of PushShift .gzip Reddit archives for .xlsx annotation. Computes Cohen's Kappa post-annotation. Permits LLM-assisted per-tag triangulation of annotation discrepancies._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6798cd51-6e0f-4952-ab6d-1dcc8d4a4212",
      "metadata": {
        "id": "6798cd51-6e0f-4952-ab6d-1dcc8d4a4212"
      },
      "source": [
        "> aim_i_annotate_triangulate_iaa.ipynb<br>\n",
        "> Simone J. Skeen (09-13-2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. [Prepare](xx)\n",
        "2. [Pre-annotation](xx)\n",
        "3. [Wave 1 (purposive)](xx)\n",
        "4. [Wave 2 (random)](xx)\n",
        "5. [Post-annotation](xx)\n",
        "6. [Human-LLM triangulation](xx)"
      ],
      "metadata": {
        "id": "ycvCXXYN4dkO"
      },
      "id": "ycvCXXYN4dkO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare"
      ],
      "metadata": {
        "id": "sxtIy5rpkyR-"
      },
      "id": "sxtIy5rpkyR-"
    },
    {
      "cell_type": "code",
      "source": [
        "    ### SJS 8/17: recreate using \"New Colab\" in Drive, reorder logically for GitHub + clean up Fx"
      ],
      "metadata": {
        "id": "9Pv24PHEYxkx"
      },
      "id": "9Pv24PHEYxkx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "\n",
        "%pip install irrCAC\n",
        "\n",
        "%pip install openai\n",
        "%pip install --upgrade openai\n",
        "\n",
        "%pip install --upgrade pydantic\n",
        "\n",
        "    ### SJS 8/13: dependency error - fix this\n",
        "\n",
        "#!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.0.0/en_core_web_lg-3.0.0.tar.gz"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oOOIgyCTkxag"
      },
      "id": "oOOIgyCTkxag",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import en_core_web_lg\n",
        "import gzip\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#import openai\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import spacy\n",
        "import time\n",
        "import warnings\n",
        "import webbrowser\n",
        "\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "from irrCAC.raw import CAC\n",
        "#from openai import OpenAI\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#spacy.cli.download('en_core_web_lg')\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "\n",
        "pd.set_option(\n",
        "              'display.max_columns',\n",
        "              None,\n",
        "              )\n",
        "pd.set_option(\n",
        "              'display.max_rows',\n",
        "              None,\n",
        "              )\n",
        "\n",
        "warnings.simplefilter(\n",
        "                      action = 'ignore',\n",
        "                      category = FutureWarning,\n",
        "                      )\n",
        "\n",
        "#!python -m prodigy stats"
      ],
      "metadata": {
        "id": "M0i2nMXlk_ur"
      },
      "id": "M0i2nMXlk_ur",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\n",
        "            '/content/drive',\n",
        "            #force_remount = True,\n",
        "            )"
      ],
      "metadata": {
        "id": "7c_Y-PPrlDQa"
      },
      "id": "7c_Y-PPrlDQa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "affd73c6-0a20-4c57-bade-c6b314610435",
      "metadata": {
        "id": "affd73c6-0a20-4c57-bade-c6b314610435"
      },
      "source": [
        "### Pre-annotation\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Import_**"
      ],
      "metadata": {
        "id": "OMSI1D-cTkig"
      },
      "id": "OMSI1D-cTkig"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5223e24d-c668-45e4-8ac1-fc4bb388c349",
      "metadata": {
        "id": "5223e24d-c668-45e4-8ac1-fc4bb388c349",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "wd = '/content/drive/MyDrive/Colab/dissertation/d_posts' ### Colab - gdrive\n",
        "\n",
        "#wd = 'C:/Users/sskee/OneDrive/Documents/02_tulane/01_research/03_prospectus/d_posts' ### Jupyter - local\n",
        "\n",
        "ds = []\n",
        "\n",
        "# loop over .json.gz\n",
        "\n",
        "for filename in os.listdir(wd):\n",
        "    if filename.endswith('.json.gz'):\n",
        "        filepath = os.path.join(\n",
        "                                wd,\n",
        "                                filename,\n",
        "                                )\n",
        "        with gzip.open(\n",
        "                       filepath,\n",
        "                       'rt', ### 'open for reading', 'text mode'\n",
        "                       encoding = 'utf-8',\n",
        "                       ) as i:\n",
        "            data = [json.loads(line) for line in i]\n",
        "            d_gz = pd.DataFrame(data)\n",
        "            ds.append(d_gz)\n",
        "\n",
        "# concatenate\n",
        "\n",
        "d = pd.concat(\n",
        "              ds,\n",
        "              ignore_index = True,\n",
        "              )\n",
        "\n",
        "# harmonize\n",
        "\n",
        "d = d.dropna(\n",
        "             axis = 1,\n",
        "             how = 'any',\n",
        "             )\n",
        "\n",
        "# de-duplicate\n",
        "\n",
        "d = d.drop_duplicates(\n",
        "                      subset = 'id',\n",
        "                      )\n",
        "\n",
        "# re-index\n",
        "\n",
        "d['date'] = pd.to_datetime(\n",
        "                           d.created_utc,\n",
        "                           unit = 's',\n",
        "                           )\n",
        "\n",
        "d.set_index(\n",
        "            'date',\n",
        "            drop = False,\n",
        "            inplace = True,\n",
        "            )\n",
        "\n",
        "# inspect\n",
        "\n",
        "d.shape\n",
        "d.dtypes\n",
        "d.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Format_**"
      ],
      "metadata": {
        "id": "iSRzM_RMTpdx"
      },
      "id": "iSRzM_RMTpdx"
    },
    {
      "cell_type": "code",
      "source": [
        "def prep(d):\n",
        "    '''Prepares d for annotation'''\n",
        "    d = d[[\n",
        "           'author',\n",
        "           'created_utc',\n",
        "           'date',\n",
        "           'id',\n",
        "           'num_comments',\n",
        "           'selftext',\n",
        "           'subreddit',\n",
        "           'title',\n",
        "           ]].copy()\n",
        "\n",
        "    d.rename(\n",
        "             columns = {\n",
        "                        'author': 'p_au',\n",
        "                        'created_utc': 'p_utc',\n",
        "                        'date': 'p_date',\n",
        "                        'id': 'p_id',\n",
        "                        'num_comments': 'n_cmnt',\n",
        "                        'selftext': 'text',\n",
        "                        'subreddit': 'sbrt',\n",
        "                        'title': 'p_titl',\n",
        "                        }, inplace = True,\n",
        "            )\n",
        "\n",
        "    d = d.assign(\n",
        "                 asp = ' ',      ### STS\n",
        "                 asp_rtnl = ' ',\n",
        "                 dep = ' ',\n",
        "                 dep_rtnl = ' ',\n",
        "                 val = ' ',\n",
        "                 val_rtnl = ' ',\n",
        "                 prg = ' ',      ### explicit\n",
        "                 tgd = ' ',\n",
        "                 age = ' ',      ### hybrid\n",
        "                 race = ' ',     ### implicit\n",
        "                 dbty = ' ',\n",
        "                 insb = ' ',     ### insubstantial\n",
        "                 )\n",
        "\n",
        "    d = d[~d['text'].isin([\n",
        "                           '[deleted]',\n",
        "                           '[removed]',\n",
        "                           ])]\n",
        "\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "c7KzzSj9jhDD"
      },
      "id": "c7KzzSj9jhDD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3926d762-394b-4ff3-a50a-fd56d40243d2",
      "metadata": {
        "id": "3926d762-394b-4ff3-a50a-fd56d40243d2"
      },
      "outputs": [],
      "source": [
        "\n",
        "d = prep(d)\n",
        "\n",
        "# restrict timeframe\n",
        "\n",
        "d = d.loc[(d['p_date'] >= '2022-01-01') & (d['p_date'] <= '2022-12-31')]\n",
        "\n",
        "# verify\n",
        "\n",
        "d.shape\n",
        "sbrt = d['sbrt'].unique()\n",
        "print(sbrt)\n",
        "d.head(1)\n",
        "d.tail(1)\n",
        "\n",
        "# plot\n",
        "\n",
        "monthly_counts = d.resample('M').sbrt.value_counts().unstack().fillna(0)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "monthly_counts.plot(\n",
        "                    kind = 'line',\n",
        "                    ax = ax,\n",
        "                    )\n",
        "\n",
        "box = ax.get_position()\n",
        "\n",
        "ax.set_position(\n",
        "                [\n",
        "                 box.x0,\n",
        "                 box.y0,\n",
        "                 box.width * 0.8,\n",
        "                 box.height,\n",
        "                 ]\n",
        "                  )\n",
        "\n",
        "ax.legend(\n",
        "          loc = 'center left',\n",
        "          bbox_to_anchor=(1, 0.5),\n",
        "          )\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Parse by subreddit_**"
      ],
      "metadata": {
        "id": "mUFzr3RDaUKC"
      },
      "id": "mUFzr3RDaUKC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47188289-5ff4-4d0a-9c9c-953312ba3f81",
      "metadata": {
        "id": "47188289-5ff4-4d0a-9c9c-953312ba3f81"
      },
      "outputs": [],
      "source": [
        "def parse(d, col):\n",
        "    '''Parses d by subreddit'''\n",
        "    uniq_val = d[col].unique()\n",
        "    sub_d = {}\n",
        "    for val in uniq_val:\n",
        "        sub_d[f'd_{val}'] = d[d[col] == val].copy()\n",
        "\n",
        "    return sub_d\n",
        "\n",
        "sub_d = parse(\n",
        "              d,\n",
        "              'sbrt',\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Subset A: strains (proxy)_**"
      ],
      "metadata": {
        "id": "DpUYKeifcTzK"
      },
      "id": "DpUYKeifcTzK"
    },
    {
      "cell_type": "code",
      "source": [
        "#d_ax = sub_d['d_Anxiety'] ### deprecated\n",
        "d_dp = sub_d['d_depression']\n",
        "#d_mh = sub_d['d_mentalhealth'] ### deprecated\n",
        "d_sw = sub_d['d_SuicideWatch']\n",
        "\n",
        "#print('r/Anxiety')\n",
        "#d_ax.shape\n",
        "print(\"\\nr/depression\")\n",
        "d_dp.shape\n",
        "#print(\"\\nr/mentalhealth\")\n",
        "#d_mh.shape\n",
        "print(\"\\nr/SuicideWatch\")\n",
        "d_sw.shape"
      ],
      "metadata": {
        "id": "FJePaFGmaJGr"
      },
      "id": "FJePaFGmaJGr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Subset B: explicit BAR targets (proxy)_**"
      ],
      "metadata": {
        "id": "hPFu-CLqccop"
      },
      "id": "hPFu-CLqccop"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62709bd-acef-4221-9253-f16241b241a5",
      "metadata": {
        "tags": [],
        "id": "f62709bd-acef-4221-9253-f16241b241a5"
      },
      "outputs": [],
      "source": [
        "d_gs = sub_d['d_TheGirlSurvivalGuide']\n",
        "d_tr = sub_d['d_trans']\n",
        "d_tx = sub_d['d_TwoXChromosomes']\n",
        "\n",
        "print(\"r/TheGirlSurvivalGuide\")\n",
        "d_gs.shape\n",
        "print(\"\\nr/Trans\")\n",
        "d_tr.shape\n",
        "print(\"\\nr/TwoXChromosomes\")\n",
        "d_tx.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_ner_redact_post_texts_**"
      ],
      "metadata": {
        "id": "rxjUgTUYr0CD"
      },
      "id": "rxjUgTUYr0CD"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "def ner_redact_post_texts(p_text):\n",
        "    ne = list(\n",
        "              [\n",
        "               'PERSON',   ### people, including fictional\n",
        "               'NORP',     ### nationalities or religious or political groups\n",
        "               'FAC',      ### buildings, airports, highways, bridges, etc.\n",
        "               'ORG',      ### companies, agencies, institutions, etc.\n",
        "               #'GPE',     ### countries, cities, states\n",
        "               'LOC',      ### non-GPE locations, mountain ranges, bodies of water\n",
        "               'PRODUCT',  ### objects, vehicles, foods, etc. (not services)\n",
        "               'EVENT',    ### named hurricanes, battles, wars, sports events, etc.\n",
        "               ]\n",
        "                )\n",
        "\n",
        "    doc = nlp(p_text)\n",
        "    ne_to_remove = []\n",
        "    final_string = str(p_text)\n",
        "    for sent in doc.ents:\n",
        "        if sent.label_ in ne:\n",
        "            ne_to_remove.append(str(sent.text))\n",
        "    for n in range(len(ne_to_remove)):\n",
        "        final_string = final_string.replace(\n",
        "                                            ne_to_remove[n],\n",
        "                                            '<|PII|>',\n",
        "                                            )\n",
        "    return final_string\n",
        "\n",
        "#d['text'] = d['text'].astype(str).apply(lambda i: ner_redact_post_texts(i))"
      ],
      "metadata": {
        "id": "c7VW7Lb-rzH6"
      },
      "id": "c7VW7Lb-rzH6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f2c4f12-d0f1-4288-978e-45b91509a53a",
      "metadata": {
        "id": "4f2c4f12-d0f1-4288-978e-45b91509a53a"
      },
      "source": [
        "### Wave 1: purposive"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ead8b73a-ea40-423d-986e-2f80f608f550",
      "metadata": {
        "id": "ead8b73a-ea40-423d-986e-2f80f608f550"
      },
      "source": [
        "#### Cycle 0: pilot (_n_ = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_r/SuicideWatch_**"
      ],
      "metadata": {
        "id": "wKGuo94OrpDI"
      },
      "id": "wKGuo94OrpDI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dbb7b26-1086-4a72-a374-7d4548066e11",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "tags": [],
        "id": "0dbb7b26-1086-4a72-a374-7d4548066e11"
      },
      "outputs": [],
      "source": [
        "'.gend\\S*|pregnan\\S*' ### a priori/canonical\n",
        "'trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe' ### inductively derived\n",
        "\n",
        "rg = re.compile('.gend\\S*|pregnan\\S*|trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe', re.I)\n",
        "\n",
        "d = d.loc[d['text'].str.contains(\n",
        "                                 rg,\n",
        "                                 regex = True,\n",
        "                                 )]\n",
        "\n",
        "d['text'] = d['text'].astype(str).apply(lambda i: redact(i))\n",
        "d.shape\n",
        "\n",
        "# export: 'd_cycle*.xlsx'\n",
        "\n",
        "os.chdir('C:/Users/sskee/OneDrive/Documents/02_tulane/01_research/03_prospectus/annotation/d_raw')\n",
        "#%pwd\n",
        "\n",
        "d.to_excel('d_cycle0.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5028f6a-24a8-40f7-a54a-780b0177f335",
      "metadata": {
        "id": "a5028f6a-24a8-40f7-a54a-780b0177f335"
      },
      "source": [
        "#### Cycle 1 (_n_ = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subset A**<br>\n",
        "r/Anxiety, r/Depression, r/MentalHealth, r/SuicideWatch\n",
        "\n",
        "**Subset B**<br>\n",
        "r/Trans"
      ],
      "metadata": {
        "id": "FiXcI80YuwDE"
      },
      "id": "FiXcI80YuwDE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafbec81-c434-4593-87dd-bdec313b1908",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "eafbec81-c434-4593-87dd-bdec313b1908"
      },
      "outputs": [],
      "source": [
        "d_a = pd.concat([\n",
        "                 d_ax,\n",
        "                 d_dp,\n",
        "                 d_mh,\n",
        "                 d_sw,\n",
        "                 ])\n",
        "\n",
        "d_a.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )\n",
        "\n",
        "d_b = d_tr.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "983c8be1-1e48-4211-a8ea-c5dbb2393a05",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "tags": [],
        "id": "983c8be1-1e48-4211-a8ea-c5dbb2393a05"
      },
      "outputs": [],
      "source": [
        "# subset A: r/anxiety, r/depression, r/mentalhealth, r/SuicideWatch\n",
        "\n",
        "'.gend\\S*|pregnan\\S*' ### a priori/canonical\n",
        "'trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe' ### inductively derived\n",
        "\n",
        "rg_a = re.compile('.gend\\S*|pregnan\\S*|trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe', re.I)\n",
        "\n",
        "d_a = d_a.loc[d_a['text'].str.contains(\n",
        "                                       rg_a,\n",
        "                                       regex = True,\n",
        "                                       )]\n",
        "\n",
        "d_a.shape\n",
        "\n",
        "# subset B: r/trans\n",
        "\n",
        "'.criminal\\S*|restrict\\S*|.law|.legal\\S*' ### a priori/canonical\n",
        "\n",
        "rg_b = re.compile('.criminal\\S*|restrict\\S*|.law|.legal\\S*', re.I)\n",
        "\n",
        "d_b = d_b.loc[d_b['text'].str.contains(\n",
        "                                       rg_b,\n",
        "                                       regex = True,\n",
        "                                       )]\n",
        "\n",
        "d_b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba376f5f-dc54-4253-858d-b40d677674c2",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "tags": [],
        "id": "ba376f5f-dc54-4253-858d-b40d677674c2"
      },
      "outputs": [],
      "source": [
        "d = pd.concat([\n",
        "               d_a, # n = 9740\n",
        "               d_b, # n = 1505\n",
        "               ])\n",
        "\n",
        "d.shape # N = 11245"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Export: 'd_cycle*.xlsx'**"
      ],
      "metadata": {
        "id": "ux5HGk7BzC1m"
      },
      "id": "ux5HGk7BzC1m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12af9766-e4e3-4b44-8ff4-7a446e9715e9",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "12af9766-e4e3-4b44-8ff4-7a446e9715e9"
      },
      "outputs": [],
      "source": [
        "d = d.sample(n = 100)\n",
        "\n",
        "d['text'] = d['text'].astype(str).apply(lambda i: redact(i))\n",
        "d.shape\n",
        "\n",
        "# export: 'd_cycle*.xlsx'\n",
        "\n",
        "os.chdir('C:/Users/sskee/OneDrive/Documents/02_tulane/01_research/03_prospectus/annotation/d_raw')\n",
        "#%pwd\n",
        "\n",
        "d.to_excel('d_cycle1.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ce88a8-8c48-4619-9b27-530961c30704",
      "metadata": {
        "id": "18ce88a8-8c48-4619-9b27-530961c30704"
      },
      "source": [
        "####Cycle 2 (_n_ = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subset A**<br>\n",
        "r/Depression, r/SuicideWatch<br>\n",
        "\n",
        "**Subset B**<br>\n",
        "r/Trans"
      ],
      "metadata": {
        "id": "nOWKSL-6gmdq"
      },
      "id": "nOWKSL-6gmdq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ee602f-c615-4c5c-a221-7f3c19532b6e",
      "metadata": {
        "id": "c3ee602f-c615-4c5c-a221-7f3c19532b6e"
      },
      "outputs": [],
      "source": [
        "d_a = pd.concat([\n",
        "                 d_dp,\n",
        "                 d_sw,\n",
        "                 ])\n",
        "\n",
        "        ### SJS 5/22: dropping r/Anxiety, r/mentalhealth\n",
        "\n",
        "d_a.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )\n",
        "\n",
        "d_b = d_tr.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2ab871f-6c39-43b0-ac38-24231efcf59e",
      "metadata": {
        "id": "f2ab871f-6c39-43b0-ac38-24231efcf59e"
      },
      "outputs": [],
      "source": [
        "# subset A\n",
        "\n",
        "'.gend\\S*|pregnan\\S*' ### a priori/canonical\n",
        "'trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe' ### inductively derived\n",
        "\n",
        "rg_a = re.compile('.gend\\S*|pregnan\\S*|trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe', re.I)\n",
        "\n",
        "d_a = d_a.loc[d_a['text'].str.contains(\n",
        "                                       rg_a,\n",
        "                                       regex = True,\n",
        "                                       )]\n",
        "\n",
        "d_a.shape\n",
        "\n",
        "# subset B\n",
        "\n",
        "'.criminal\\S*|restrict\\S*|illegal\\S*|outlaw\\S*|suicid\\S*' ### a priori/canonical\n",
        "\n",
        "rg_b = re.compile('.criminal\\S*|restrict\\S*|illegal\\S*|outlaw\\S*|suicid\\S*', re.I)\n",
        "\n",
        "d_b = d_b.loc[d_b['text'].str.contains(\n",
        "                                       rg_b,\n",
        "                                       regex = True,\n",
        "                                       )]\n",
        "\n",
        "d_b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8964d6f-f254-4358-b37f-69f8ea317c93",
      "metadata": {
        "id": "c8964d6f-f254-4358-b37f-69f8ea317c93"
      },
      "outputs": [],
      "source": [
        "d = pd.concat([\n",
        "               d_a, # n = 5602\n",
        "               d_b, # n = 729\n",
        "               ])\n",
        "\n",
        "d.shape # N = 11245"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Export: 'd_cycle*.xlsx'**"
      ],
      "metadata": {
        "id": "be1AwjXmy_La"
      },
      "id": "be1AwjXmy_La"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927c9db4-14e1-49b4-ba2f-f5f0ab6a7379",
      "metadata": {
        "id": "927c9db4-14e1-49b4-ba2f-f5f0ab6a7379"
      },
      "outputs": [],
      "source": [
        "d = d.sample(n = 100)\n",
        "\n",
        "d['text'] = d['text'].astype(str).apply(lambda i: redact(i))\n",
        "\n",
        "# export: 'd_cycle*.xlsx'\n",
        "\n",
        "os.chdir('C:/Users/sskee/OneDrive/Documents/02_tulane/01_research/03_prospectus/annotation/d_raw')\n",
        "#%pwd\n",
        "\n",
        "d.to_excel('d_cycle2.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cycle 3 (_n_ = 150)"
      ],
      "metadata": {
        "id": "2shHgKynpQeT"
      },
      "id": "2shHgKynpQeT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subset A**<br>\n",
        "r/Depression, r/SuicideWatch<br>\n",
        "\n",
        "**Subset B**<br>\n",
        "r/TheGirlsSurvivalGuide, r/Trans, r/TwoXChromosomes"
      ],
      "metadata": {
        "id": "XLBtV8Yftiu8"
      },
      "id": "XLBtV8Yftiu8"
    },
    {
      "cell_type": "code",
      "source": [
        "d_a = pd.concat([\n",
        "                 d_dp,\n",
        "                 d_sw,\n",
        "                 ])\n",
        "\n",
        "d_a.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )\n",
        "\n",
        "d_b = pd.concat([\n",
        "                 d_gs,\n",
        "                 d_tr,\n",
        "                 d_tx,\n",
        "                 ])\n",
        "\n",
        "d_b.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )"
      ],
      "metadata": {
        "id": "IYAzTh5TqdJI"
      },
      "id": "IYAzTh5TqdJI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subset A\n",
        "\n",
        "'.gend\\S*|pregnan\\S*' ### a priori/canonical\n",
        "'trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe' ### inductively derived\n",
        "\n",
        "rg_a = re.compile('.gend\\S*|pregnan\\S*|trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe', re.I)\n",
        "\n",
        "d_a = d_a.loc[d_a['text'].str.contains(\n",
        "                                       rg_a,\n",
        "                                       regex = True,\n",
        "                                       )]\n",
        "\n",
        "d_a.shape\n",
        "\n",
        "# subset B\n",
        "\n",
        "'.criminal\\S*|restrict\\S*|illegal\\S*|outlaw\\S*|suicid\\S*' ### a priori/canonical\n",
        "\n",
        "rg_b = re.compile('.criminal\\S*|restrict\\S*|illegal\\S*|outlaw\\S*|suicid\\S*', re.I)\n",
        "\n",
        "d_b = d_b.loc[d_b['text'].str.contains(\n",
        "                                       rg_b,\n",
        "                                       regex = True,\n",
        "                                       )]\n",
        "\n",
        "d_b.shape"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OpTUs671hR-p"
      },
      "id": "OpTUs671hR-p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.concat([\n",
        "               d_a, # n = 5602\n",
        "               d_b, # n = 1971\n",
        "               ])\n",
        "\n",
        "d.shape # N = 7573"
      ],
      "metadata": {
        "id": "J1tW8ghThSCs"
      },
      "id": "J1tW8ghThSCs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Export: 'd_cycle*.xlsx'**"
      ],
      "metadata": {
        "id": "9XpPMuchxCd_"
      },
      "id": "9XpPMuchxCd_"
    },
    {
      "cell_type": "code",
      "source": [
        "d = d.sample(n = 150)\n",
        "\n",
        "d['text'] = d['text'].astype(str).apply(lambda i: redact(i))\n",
        "\n",
        "#os.chdir('C:/Users/sskee/OneDrive/Documents/02_tulane/01_research/03_prospectus/annotation/d_raw')\n",
        "#%pwd\n",
        "\n",
        "%cd gdrive/My Drive/Colab/prospectus/annotation/d_raw\n",
        "\n",
        "d.to_excel('d_cycle3.xlsx')"
      ],
      "metadata": {
        "id": "RttpdblchSH-"
      },
      "id": "RttpdblchSH-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random subset - Cycle 999\n",
        "\n",
        "d_999 = d.sample(n = 1000)\n",
        "\n",
        "d_999['text'] = d_999['text'].astype(str).apply(lambda i: redact(i))\n",
        "\n",
        "d_999.to_excel('d_cycle999.xlsx')"
      ],
      "metadata": {
        "id": "_jBCboc-wG6e"
      },
      "id": "_jBCboc-wG6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cycle 4 (_n_ = 150)"
      ],
      "metadata": {
        "id": "Qt5CDZn-b_qY"
      },
      "id": "Qt5CDZn-b_qY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supplementing _prg_**"
      ],
      "metadata": {
        "id": "WQ4Yg--q37V-"
      },
      "id": "WQ4Yg--q37V-"
    },
    {
      "cell_type": "code",
      "source": [
        "# inspecting new _prg_ foregrounding subreddits...\n",
        "\n",
        "    ### SJS 7/15: 2022 for now\n",
        "\n",
        "%cd /content/gdrive/My Drive/Colab/dissertation/d_posts\n",
        "\n",
        "d_aw = pd.read_json(\n",
        "                    #'r_thegirlsurvivalguide_posts.jsonl', # d_gs.xlsx\n",
        "                    #'r_confession_posts.jsonl', # d_co.xlsx\n",
        "                    'r_askwomenadvice_posts.jsonl', # d_aw.xlsx\n",
        "                    #'r_traumatoolbox_posts.jsonl', # d_tb.xlsx\n",
        "                    #'r_birthcontrol_posts.jsonl', # d_bc.xlsx\n",
        "                    #'r_WomensHealth_posts.jsonl', # d_wh.xlsx\n",
        "                    lines = True,\n",
        "                    )\n",
        "\n",
        "    ### SJS 7/15: decision: adding r_askwomenadvice to Cycle 4\n",
        "\n",
        "d_aw.shape\n",
        "d_aw.head(3)\n",
        "d_aw.tail(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0VFnSW9Pb-8d"
      },
      "id": "0VFnSW9Pb-8d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# harmonize\n",
        "\n",
        "d_aw = d_aw.dropna(\n",
        "                   axis = 1,\n",
        "                   how = 'any',\n",
        "                   )\n",
        "\n",
        "# de-duplicate\n",
        "\n",
        "d_aw = d_aw.drop_duplicates(\n",
        "                            subset = 'id',\n",
        "                            )\n",
        "\n",
        "# re-index\n",
        "\n",
        "d_aw['date'] = pd.to_datetime(\n",
        "                              d_aw.created_utc,\n",
        "                              unit = 's',\n",
        "                              )\n",
        "\n",
        "d_aw.set_index(\n",
        "               'date',\n",
        "               drop = False,\n",
        "               inplace = True,\n",
        "               )\n",
        "\n",
        "#d.shape\n",
        "#d.head(3)\n",
        "\n",
        "d_aw = prep(d_aw)\n",
        "\n",
        "#d.shape\n",
        "#d.head(3)\n",
        "\n",
        "d_aw['text'] = d_aw['text'].astype(str).apply(lambda i: redact(i))\n",
        "#d_gs['text'] = d_gs['text'].astype(str).apply(lambda i: redact(i))\n",
        "\n",
        "d_aw.shape\n",
        "d_aw.head(3)\n",
        "d_aw.tail(3)\n",
        "\n",
        "#d_gs.shape\n",
        "#d_gs.head(3)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lN85tPWPcCuq"
      },
      "id": "lN85tPWPcCuq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_dp.shape\n",
        "d_dp.head(3)\n",
        "d_sw.shape\n",
        "d_sw.head(3)\n",
        "\n",
        "d_gs.shape\n",
        "d_gs.head(3)\n",
        "d_tr.shape\n",
        "d_tr.head(3)\n",
        "d_tx.shape\n",
        "d_tx.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "t2Nw8LjqLUaP"
      },
      "id": "t2Nw8LjqLUaP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Subset A: strains**<br>\n",
        "r/Depression, r/SuicideWatch<br>\n",
        "\n",
        "**Subset B: explicit targeting**<br>\n",
        "r/AskWomenAdvice, r/TheGirlsSurvivalGuide, r/Trans, r/TwoXChromosomes"
      ],
      "metadata": {
        "id": "qsQhzhS1Fs5p"
      },
      "id": "qsQhzhS1Fs5p"
    },
    {
      "cell_type": "code",
      "source": [
        "d_a = pd.concat([\n",
        "                 d_dp,\n",
        "                 d_sw,\n",
        "                 ])\n",
        "\n",
        "d_a.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )\n",
        "\n",
        "d_b = pd.concat([\n",
        "                 d_tr,\n",
        "                 d_tx,\n",
        "                 ])\n",
        "\n",
        "d_b.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )\n",
        "\n",
        "    ### SJS 7/16: giving an artifical boost to these two (n = 20)\n",
        "\n",
        "d_c = pd.concat([\n",
        "                 d_aw,\n",
        "                 d_gs,\n",
        "                 ])\n",
        "\n",
        "d_c.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )\n"
      ],
      "metadata": {
        "id": "YAHBzg8KcC6-"
      },
      "id": "YAHBzg8KcC6-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_a = shuffle(d_a)\n",
        "d_a.head(10)\n",
        "#d_a.sample(10)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C_iZ9OUCwlFu"
      },
      "id": "C_iZ9OUCwlFu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_b = shuffle(d_b)\n",
        "d_b.head(10)\n",
        "#d_b.sample(10)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yDlePyWLwlTm"
      },
      "id": "yDlePyWLwlTm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_c = shuffle(d_c)\n",
        "d_c.head(10)\n",
        "#d_c.sample(10)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "A0ePz7Jm6pGg"
      },
      "id": "A0ePz7Jm6pGg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subset A\n",
        "\n",
        "'.gend\\S*|pregnan\\S*' ### a priori/canonical\n",
        "'trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe' ### inductively derived\n",
        "\n",
        "rg_a = re.compile('.gend\\S*|pregnan\\S*|trans|non-?binary|dysphor\\S*|hormone|abort\\S*|dobbs|roe', re.I)\n",
        "\n",
        "d_a = d_a.loc[d_a['text'].str.contains(\n",
        "                                       rg_a,\n",
        "                                       regex = True,\n",
        "                                       )]\n",
        "\n",
        "d_a.shape\n",
        "\n",
        "# subset B+\n",
        "\n",
        "'.criminal\\S*|restrict\\S*|illegal\\S*|outlaw\\S*|suicid\\S*|dobbs|roe|pregnan\\S*' ### a priori/canonical\n",
        "\n",
        "rg_b = re.compile('.criminal\\S*|restrict\\S*|illegal\\S*|outlaw\\S*|suicid\\S*|dobbs|roe|pregnan\\S*', re.I)\n",
        "\n",
        "d_b = d_b.loc[d_b['text'].str.contains(\n",
        "                                       rg_b,\n",
        "                                       regex = True,\n",
        "                                       )]\n",
        "\n",
        "d_b.shape\n",
        "\n",
        "d_c = d_c.loc[d_c['text'].str.contains(\n",
        "                                       rg_b,\n",
        "                                       regex = True,\n",
        "                                       )]\n",
        "\n",
        "d_c.shape"
      ],
      "metadata": {
        "id": "FQBJlh2sGBsp"
      },
      "id": "FQBJlh2sGBsp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.concat([\n",
        "               d_a, # n = 5602\n",
        "               d_b, # n = 5478\n",
        "               ])\n",
        "\n",
        "d.shape # N = 11080"
      ],
      "metadata": {
        "id": "kHLQHEynGBv3"
      },
      "id": "kHLQHEynGBv3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Export: 'd_cycle*.xlsx'**"
      ],
      "metadata": {
        "id": "PPtcS2JdHtdH"
      },
      "id": "PPtcS2JdHtdH"
    },
    {
      "cell_type": "code",
      "source": [
        "d = d.sample(n = 130)\n",
        "\n",
        "d['text'] = d['text'].astype(str).apply(lambda i: redact(i))\n"
      ],
      "metadata": {
        "id": "K-9BPPMeGB0c"
      },
      "id": "K-9BPPMeGB0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# supplementing Cycle 4\n",
        "\n",
        "d_suppl = d_c.sample(n = 20)\n",
        "\n",
        "d_suppl['text'] = d_suppl['text'].astype(str).apply(lambda i: redact(i))"
      ],
      "metadata": {
        "id": "qLvxsxDZGB4q"
      },
      "id": "qLvxsxDZGB4q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# supplementing Cycle 999 (training data)\n",
        "\n",
        "%cd /content/gdrive/My Drive/Colab/prospectus/annotation/d_raw\n",
        "\n",
        "d_suppl = d_c.sample(n = 200)\n",
        "#d_suppl['text'] = d_suppl['text'].astype(str).apply(lambda i: redact(i))\n",
        "d_suppl.to_excel('d_cycle999_suppl.xlsx')"
      ],
      "metadata": {
        "id": "zdJ2-Pwe4XfI"
      },
      "id": "zdJ2-Pwe4XfI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.concat([\n",
        "               d, # n = 130\n",
        "               d_suppl, # n = 20\n",
        "               ])\n",
        "\n",
        "d.shape # N = xx"
      ],
      "metadata": {
        "id": "XOqcmu1k8z3N"
      },
      "id": "XOqcmu1k8z3N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = shuffle(d)"
      ],
      "metadata": {
        "id": "vkwfNBEAADfd"
      },
      "id": "vkwfNBEAADfd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/Colab/prospectus/annotation/d_raw\n",
        "\n",
        "d.to_excel('d_cycle4.xlsx')"
      ],
      "metadata": {
        "id": "_AjFWZIoGB83"
      },
      "id": "_AjFWZIoGB83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wave 2: random"
      ],
      "metadata": {
        "id": "HP08u7N-l3MC"
      },
      "id": "HP08u7N-l3MC"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab/dissertation/d_posts\n",
        "\n",
        "d_aw = pd.read_excel('d_aw.xlsx')\n",
        "\n",
        "d_aw.shape\n",
        "d_aw.head(3)\n",
        "d_aw.tail(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "W5nEDqrrr98o"
      },
      "id": "W5nEDqrrr98o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    ### SJS 8/15: same _prg_ oversampling strategy: 1000 random fr d_a and d_b, plus 200 from r/GSG and r/AWA\n",
        "\n",
        "d_dp.shape\n",
        "d_dp.head(3)\n",
        "d_sw.shape\n",
        "d_sw.head(3)\n",
        "\n",
        "d_aw.shape\n",
        "d_aw.head(3)\n",
        "d_gs.shape\n",
        "d_gs.head(3)\n",
        "d_tr.shape\n",
        "d_tr.head(3)\n",
        "d_tx.shape\n",
        "d_tx.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EOTT0mmjsinG"
      },
      "id": "EOTT0mmjsinG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_a = pd.concat([\n",
        "                 d_dp, ### r/depression\n",
        "                 d_sw, ### r/SuicideWatch\n",
        "                 ])\n",
        "\n",
        "d_a = shuffle(d_a)\n",
        "\n",
        "d_a.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )\n",
        "\n",
        "d_b = pd.concat([\n",
        "                 d_tr, ### r/trans\n",
        "                 d_tx, ### r/TwoXChromosomes\n",
        "                 ])\n",
        "\n",
        "d_b = shuffle(d_b)\n",
        "\n",
        "d_b.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )\n",
        "\n",
        "d_c = pd.concat([\n",
        "                 d_aw, ### r/AskWomenAdvice,\n",
        "                 d_gs, ### r/TheGirlsSurvivalGuide\n",
        "                 ])\n",
        "\n",
        "d_c = shuffle(d_c)\n",
        "\n",
        "d_c.reset_index(\n",
        "                drop = True,\n",
        "                inplace = True,\n",
        "                )\n",
        "\n",
        "d_a.shape\n",
        "d_b.shape\n",
        "d_c.shape"
      ],
      "metadata": {
        "id": "_KDw5q7LsitZ"
      },
      "id": "_KDw5q7LsitZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_a.head(3)\n",
        "d_b.head(3)\n",
        "\n",
        "#d_c = d_c.drop(\n",
        "#               'date',\n",
        "#               axis = 1,\n",
        "#               )\n",
        "\n",
        "d_c.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hWyNS7UqwnIZ"
      },
      "id": "hWyNS7UqwnIZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.concat([\n",
        "               d_a, # n = 178030\n",
        "               d_b, # n = 110213\n",
        "               ])\n",
        "\n",
        "d.shape # N = 288243"
      ],
      "metadata": {
        "id": "s_JuQ1RVsiyU"
      },
      "id": "s_JuQ1RVsiyU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = d.sample(n = 1000)\n",
        "\n",
        "d['text'] = d['text'].astype(str).apply(lambda i: ner_redact_post_texts(i))\n",
        "\n",
        "d.shape # N = 1000"
      ],
      "metadata": {
        "id": "SowY5IbPuImC"
      },
      "id": "SowY5IbPuImC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_suppl = d_c.sample(n = 200)\n",
        "\n",
        "d_suppl['text'] = d_suppl['text'].astype(str).apply(lambda i: ner_redact_post_texts(i))\n",
        "\n",
        "d_suppl.shape # N = 200"
      ],
      "metadata": {
        "id": "-X1RrKVouIsW"
      },
      "id": "-X1RrKVouIsW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.concat([\n",
        "               d, # n = 1000\n",
        "               d_suppl, # n = 200\n",
        "               ])\n",
        "\n",
        "d.shape # N = 1200"
      ],
      "metadata": {
        "id": "4xrcf_NduIxq"
      },
      "id": "4xrcf_NduIxq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab/dissertation/annotation/d_raw\n",
        "\n",
        "d.to_excel('d_cycle999_rnd.xlsx')"
      ],
      "metadata": {
        "id": "hg8encd5xOUI"
      },
      "id": "hg8encd5xOUI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "db7f1217-bbf0-4f7a-9de4-9a82bfc7ed9d",
      "metadata": {
        "id": "db7f1217-bbf0-4f7a-9de4-9a82bfc7ed9d"
      },
      "source": [
        "### Post-annotation\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Import_**"
      ],
      "metadata": {
        "id": "z3o5HZ4LljOF"
      },
      "id": "z3o5HZ4LljOF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c211cd41-b7a4-41b1-80d3-c6e27890ed61",
      "metadata": {
        "tags": [],
        "id": "c211cd41-b7a4-41b1-80d3-c6e27890ed61"
      },
      "outputs": [],
      "source": [
        "\n",
        "    ### SJS 7/23: old, but use for pre-negotiation kappa, then define GPT-4o Fx, then split and annotate d_dis etc\n",
        "\n",
        "    ### SJS 7/23: convention: d_iaa_cycle* for pre-GPT; d_iaa_gpt_cycle* for post-GPT negotiated\n",
        "\n",
        "\n",
        "%cd /content/drive/My Drive/Colab/bar_policy_suicidality/inputs/annotation\n",
        "\n",
        "d_sd = pd.read_excel('d_cycle1_sd.xlsx')\n",
        "#d_sd.dtypes\n",
        "\n",
        "#d_sd = d_sd.replace(' ', 0)\n",
        "d_sd.columns = [f'{col}_sd' for col in d_sd.columns]\n",
        "\n",
        "\n",
        "d_ss = pd.read_excel('d_cycle1_ss.xlsx')\n",
        "#d_ss.dtypes\n",
        "\n",
        "#d_ss = d_ss.replace(' ', 0)\n",
        "d_ss.columns = [f'{col}_ss' for col in d_ss.columns]\n",
        "\n",
        "# inspect\n",
        "\n",
        "#d_sd.head(3)\n",
        "#d_ss.head(3)\n",
        "\n",
        "# merge\n",
        "\n",
        "d = pd.merge(\n",
        "             d_sd,\n",
        "             d_ss,\n",
        "             left_index = True,\n",
        "             right_index = True,\n",
        "             )\n",
        "\n",
        "targets = [\n",
        "           'asp_sd', 'asp_ss',\n",
        "           'dep_sd', 'dep_ss',\n",
        "           'val_sd', 'val_ss',\n",
        "           'prg_sd', 'prg_ss',\n",
        "           'tgd_sd', 'tgd_ss',\n",
        "           'age_sd', 'age_ss',\n",
        "           'race_sd', 'race_ss',\n",
        "           'dbty_sd', 'dbty_ss',\n",
        "           'insb_sd', 'insb_ss',\n",
        "            ]\n",
        "\n",
        "#d = d[targets].copy()\n",
        "\n",
        "d[targets] = d[targets].apply(\n",
        "                              pd.to_numeric,\n",
        "                              errors = 'coerce',\n",
        "                              )\n",
        "\n",
        "d = d.fillna(0)\n",
        "d = d.replace(' ', 0)\n",
        "#d = d.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "d = d[[\n",
        "        #targets,\n",
        "        'p_id_sd', 'p_id_ss', ### sense-check for bad merge\n",
        "        'text_sd',\n",
        "        'asp_sd', 'asp_ss',\n",
        "        'asp_rtnl_sd', 'asp_rtnl_ss',\n",
        "        'dep_sd', 'dep_ss',\n",
        "        'dep_rtnl_sd', 'dep_rtnl_ss',\n",
        "        'val_sd', 'val_ss',\n",
        "        'val_rtnl_sd', 'val_rtnl_ss',\n",
        "        'prg_sd', 'prg_ss',\n",
        "        'tgd_sd', 'tgd_ss',\n",
        "        'age_sd', 'age_ss',\n",
        "        'race_sd', 'race_ss',\n",
        "        'dbty_sd', 'dbty_ss',\n",
        "        'insb_sd', 'insb_ss',\n",
        "        ]].copy()\n",
        "\n",
        "d.rename(\n",
        "           columns = {\n",
        "                      'p_id_sd': 'p_id',\n",
        "                      'text_sd': 'text',\n",
        "                      }, inplace = True,\n",
        "          )\n",
        "\n",
        "#d.to_excel('iaa_inspect.xlsx')\n",
        "\n",
        "# drop insb = 1 (either annotator)\n",
        "\n",
        "#d = d[(d['insb_sd'] != 1) & (d['insb_ss'] != 1)]\n",
        "\n",
        "# target = 0 for insb = 1 (either annotator)\n",
        "\n",
        "# condition to check where either 'insb_sd' or 'insb_ss' is 1\n",
        "\n",
        "condition = (d['insb_sd'] == 1) | (d['insb_ss'] == 1)\n",
        "\n",
        "# update 'asp', 'dep', and 'val' to 0 where the condition is True\n",
        "\n",
        "d.loc[condition, ['asp', 'val', 'dep']] = 0\n",
        "\n",
        "\n",
        "'n valid'\n",
        "d.shape\n",
        "\n",
        "# convert to numpy array\n",
        "\n",
        "#for target in targets:\n",
        "#    target = d[target].to_numpy()\n",
        "\n",
        "# kappa Fx\n",
        "\n",
        "def calculate_kappa(d, col_sd, col_ss):\n",
        "    return cohen_kappa_score(d[col_sd], d[col_ss])\n",
        "\n",
        "# initialize SD-SJS col pair list\n",
        "\n",
        "column_pairs = [\n",
        "                ('asp_sd', 'asp_ss'),\n",
        "                ('dep_sd', 'dep_ss'),\n",
        "                ('val_sd', 'val_ss'),\n",
        "                #('prg_sd', 'prg_ss'),\n",
        "                #('tgd_sd', 'tgd_ss'),\n",
        "                #('age_sd', 'age_ss'),\n",
        "                #('race_sd', 'race_ss'),\n",
        "                #('dbty_sd', 'dbty_ss'),\n",
        "                ]\n",
        "\n",
        "# initialize dict\n",
        "\n",
        "kappa_results = {}\n",
        "\n",
        "# kappa loop\n",
        "\n",
        "for col_sd, col_ss in column_pairs:\n",
        "    kappa = calculate_kappa(d, col_sd, col_ss)\n",
        "    kappa_results[f'{col_sd} and {col_ss}'] = kappa\n",
        "\n",
        "for pair, kappa in kappa_results.items():\n",
        "    print(f\"Cohen's Kappa for {pair}: {kappa:.2f}\")\n",
        "\n",
        "\n",
        "# dummy disagreement Fx\n",
        "\n",
        "def d_disagree(row):\n",
        "    return 1 if row[0] != row[1] else 0\n",
        "\n",
        "sts_pairs = [('asp_sd', 'asp_ss', 'asp_dis'),\n",
        "             ('dep_sd', 'dep_ss', 'dep_dis'),\n",
        "             ('val_sd', 'val_ss', 'val_dis')]\n",
        "\n",
        "for col1, col2, dis_col in sts_pairs:\n",
        "    d[dis_col] = d[[col1, col2]].apply(d_disagree, axis = 1)\n",
        "\n",
        "#d.to_excel('iaa_cycle3.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab/bar_policy_suicidality/inputs/annotation\n",
        "\n",
        "d_sd = pd.read_excel('d_cycle4_sd.xlsx')\n",
        "# d_sd.dtypes\n",
        "\n",
        "# d_sd = d_sd.replace(' ', 0)\n",
        "d_sd.columns = [f'{col}_sd' for col in d_sd.columns]\n",
        "\n",
        "d_ss = pd.read_excel('d_cycle4_ss.xlsx')\n",
        "# d_ss.dtypes\n",
        "\n",
        "# d_ss = d_ss.replace(' ', 0)\n",
        "d_ss.columns = [f'{col}_ss' for col in d_ss.columns]\n",
        "\n",
        "# inspect\n",
        "\n",
        "# d_sd.head(3)\n",
        "# d_ss.head(3)\n",
        "\n",
        "# merge\n",
        "\n",
        "d = pd.merge(\n",
        "    d_sd,\n",
        "    d_ss,\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        ")\n",
        "\n",
        "targets = [\n",
        "    'asp_sd', 'asp_ss',\n",
        "    'dep_sd', 'dep_ss',\n",
        "    'val_sd', 'val_ss',\n",
        "    'prg_sd', 'prg_ss',\n",
        "    'tgd_sd', 'tgd_ss',\n",
        "    'age_sd', 'age_ss',\n",
        "    'race_sd', 'race_ss',\n",
        "    'dbty_sd', 'dbty_ss',\n",
        "    'insb_sd', 'insb_ss',\n",
        "]\n",
        "\n",
        "# d = d[targets].copy()\n",
        "\n",
        "d[targets] = d[targets].apply(\n",
        "    pd.to_numeric,\n",
        "    errors='coerce',\n",
        ")\n",
        "\n",
        "d = d.fillna(0)\n",
        "d = d.replace(' ', 0)\n",
        "# d = d.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "d = d[[\n",
        "    # targets,\n",
        "    'p_id_sd', 'p_id_ss',  # sense-check for bad merge\n",
        "    'text_sd',\n",
        "    'asp_sd', 'asp_ss',\n",
        "    'asp_rtnl_sd', 'asp_rtnl_ss',\n",
        "    'dep_sd', 'dep_ss',\n",
        "    'dep_rtnl_sd', 'dep_rtnl_ss',\n",
        "    'val_sd', 'val_ss',\n",
        "    'val_rtnl_sd', 'val_rtnl_ss',\n",
        "    'prg_sd', 'prg_ss',\n",
        "    'tgd_sd', 'tgd_ss',\n",
        "    'age_sd', 'age_ss',\n",
        "    'race_sd', 'race_ss',\n",
        "    'dbty_sd', 'dbty_ss',\n",
        "    'insb_sd', 'insb_ss',\n",
        "]].copy()\n",
        "\n",
        "d.rename(\n",
        "    columns={\n",
        "        'p_id_sd': 'p_id',\n",
        "        'text_sd': 'text',\n",
        "    }, inplace=True,\n",
        ")\n",
        "\n",
        "# d.to_excel('iaa_inspect.xlsx')\n",
        "\n",
        "# drop insb = 1 (either annotator)\n",
        "\n",
        "# d = d[(d['insb_sd'] != 1) & (d['insb_ss'] != 1)]\n",
        "\n",
        "# target = 0 for insb = 1 (either annotator)\n",
        "\n",
        "condition = (d['insb_sd'] == 1) | (d['insb_ss'] == 1)\n",
        "\n",
        "# update 'asp', 'dep', and 'val' to 0 where insb = 1 (either annotator)\n",
        "\n",
        "d.loc[condition, ['asp', 'val', 'dep']] = 0\n",
        "\n",
        "'n valid'\n",
        "d.shape\n",
        "\n",
        "# to numpy\n",
        "\n",
        "# for target in targets:\n",
        "#     target = d[target].to_numpy()\n",
        "\n",
        "# kappa Fx\n",
        "\n",
        "def calculate_kappa(d, col_sd, col_ss):\n",
        "    return cohen_kappa_score(d[col_sd], d[col_ss])\n",
        "\n",
        "# initialize SD-SJS col pair list\n",
        "\n",
        "column_pairs = [\n",
        "    ('asp_sd', 'asp_ss'),\n",
        "    ('dep_sd', 'dep_ss'),\n",
        "    ('val_sd', 'val_ss'),\n",
        "    # ('prg_sd', 'prg_ss'),\n",
        "    # ('tgd_sd', 'tgd_ss'),\n",
        "    # ('age_sd', 'age_ss'),\n",
        "    # ('race_sd', 'race_ss'),\n",
        "    # ('dbty_sd', 'dbty_ss'),\n",
        "]\n",
        "\n",
        "# initialize dict\n",
        "\n",
        "kappa_results = {}\n",
        "\n",
        "# kappa loop\n",
        "\n",
        "for col_sd, col_ss in column_pairs:\n",
        "    kappa = calculate_kappa(d, col_sd, col_ss)\n",
        "    kappa_results[f'{col_sd} and {col_ss}'] = kappa\n",
        "\n",
        "for pair, kappa in kappa_results.items():\n",
        "    print(f\"Cohen's Kappa for {pair}: {kappa:.2f}\")\n",
        "\n",
        "\n",
        "# dummy disagreement Fx\n",
        "\n",
        "def d_disagree(row):\n",
        "    return 1 if row[0] != row[1] else 0\n",
        "\n",
        "sts_pairs = [('asp_sd', 'asp_ss', 'asp_dis'),\n",
        "             #('dep_sd', 'dep_ss', 'dep_dis'),\n",
        "             ('val_sd', 'val_ss', 'val_dis')]\n",
        "\n",
        "for col1, col2, dis_col in sts_pairs:\n",
        "    d[dis_col] = d[[col1, col2]].apply(d_disagree, axis=1)\n",
        "\n",
        "# d.to_excel('iaa_cycle3.xlsx')"
      ],
      "metadata": {
        "id": "dK5O9kdOn5WZ"
      },
      "id": "dK5O9kdOn5WZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Human-LLM triangulation"
      ],
      "metadata": {
        "id": "lenRnSUhlrdb"
      },
      "id": "lenRnSUhlrdb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Formulate 'asp' prompt_**"
      ],
      "metadata": {
        "id": "bZ-FlRzZ4hz3"
      },
      "id": "bZ-FlRzZ4hz3"
    },
    {
      "cell_type": "code",
      "source": [
        "role = '''\n",
        "You are tasked with applying qualitative codes to social media posts to categorize whether each post contains an expression of _aspiration strain_.\n",
        "'''\n",
        "\n",
        "definition = '''\n",
        "Definition of aspiration strain: 'any description of ambition, futurity, idealized or speculative lifecourse trajectories, or personal,\n",
        "professional, familial goals driving psychological strain and/or self-destructive cognitions.' Descriptions can be explicit or implicit.\n",
        "'''\n",
        "\n",
        "instruction = '''\n",
        "Below I instruct on how to apply the codes.\n",
        "\n",
        "Respond with 'asp_1' if the post contains an expression of aspiration strain, and '0' if it does not.\n",
        "\n",
        "You must choose a 'asp_1' or a '0' response.\n",
        "\n",
        "If your response is 'asp_1,' then begin a new paragraph with 'asp_rationale' and excerpt the sentences or phrases that are the _most expressive of\n",
        "aspiration strain_. You are allowed to choose multiple sentences or phrases, divided by an '<SPL>' token.\n",
        "\n",
        "If your response is 'asp_1,' then begin a new paragraph with 'strained aspirations:' and concisely name the strained aspiration that is driving the distressful\n",
        "cognitions.\n",
        "\n",
        "Then, whether you have selected a 'asp_1' or a '0,' begin a new paragraph with 'asp_explanation:' and provide a two sentence explanation for your response.\n",
        "'''\n",
        "\n",
        "clarification = '''\n",
        "Here are additional clarifying points based in human expertise:\n",
        "-\tRegret over, or wishing to redo, a past decision does _not_ warrant a 'asp_1' response\n",
        "-\tAspiration for physical impossibility (time travel, age reversion), does not warrant a 'asp_1' response\n",
        "-\tSparse decontextualized expressions of loneliness (e.g. 'I am lonely') do not warrant a 'asp_1' response; recognition of need or yearning for\n",
        "friendship, community, and/or intimacy must be explicit to warrant a 'asp_1' response\n",
        "-\tSparse decontextualized desire for a different assigned sex at birth does not warrant a 'asp_1' response; desire for gender transition or\n",
        "gender-expansive expression must be explicit.\n",
        "- Perceived inability to die by suicide does not warrant a 'asp_1' response\n",
        "'''\n",
        "\n",
        "asp_prompt = f'{role}{definition}{instruction}{clarification}'\n",
        "#print(prompt)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T0RmBhb_4fmj"
      },
      "id": "T0RmBhb_4fmj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Formulate 'val' prompt_**"
      ],
      "metadata": {
        "id": "sDZyFuRwMMGH"
      },
      "id": "sDZyFuRwMMGH"
    },
    {
      "cell_type": "code",
      "source": [
        "role = '''\n",
        "You are tasked with applying qualitative codes to social media posts to categorize whether each post contains an expression of _value strain_.\n",
        "'''\n",
        "\n",
        "definition = '''\n",
        "Definition of aspiration strain: 'any description of conflicting ideologies, norms, mores, morals, ethics, principles, or ontologies, particularly\n",
        "along traditionalist-authoritarian versus progressive-liberatory axes, driving intra-psychic strain and/or self-destructive cognitions..' Descriptions\n",
        "can be explicit or implicit.\n",
        "'''\n",
        "\n",
        "instruction = '''\n",
        "Below I instruct on how to apply the codes.\n",
        "\n",
        "Respond with 'val_1' if the post contains an expression of value strain, and '0' if it does not.\n",
        "\n",
        "You must choose a 'val_1' or a '0' response.\n",
        "\n",
        "If your response is 'val_1,' then begin a new paragraph with 'val_rationale:' and excerpt the sentences or phrases that are the _most expressive of\n",
        "value strain_. You are allowed to choose multiple sentences or phrases, divided by an '<SPL>' token.\n",
        "\n",
        "If your response is 'val_1,' then begin a new paragraph with 'strained values:' and concisely name the strained value that is driving the distressful\n",
        "cognitions.\n",
        "\n",
        "Then, whether you have selected a 'val_1' or a '0,' begin a new paragraph with 'val_explanation:' and provide a two sentence explanation for your response.\n",
        "'''\n",
        "\n",
        "clarification = '''\n",
        "Here are additional clarifying points based in human expertise:\n",
        "-\ta 'val_1' response refer to interpersonal ideological discord and/or internalized ideologically determined self-denigration\n",
        "-\tAnticipated value strain does warrant a 'val_1' response\n",
        "-\tFamilial conflict alone is insufficient to warrant a 'val_1' response\n",
        "-\tPerceived failure to uphold self-imposed expectations is insufficient to warrant a 'val_1' response\n",
        "-\tStress or tension over legality of decisions, necessities does warrant a 'val_1' response\n",
        "-\tideological or normative aspect must be explicit\n",
        "'''\n",
        "\n",
        "val_prompt = f'{role}{definition}{instruction}{clarification}'\n",
        "#print(prompt)"
      ],
      "metadata": {
        "id": "BGeLguP1MLCQ"
      },
      "id": "BGeLguP1MLCQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Define function_**"
      ],
      "metadata": {
        "id": "p9uHMi2R4qBL"
      },
      "id": "p9uHMi2R4qBL"
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = '<api_key>' ### project = skeen_prospectus; name = annotate\n",
        "client = OpenAI(api_key = api_key)\n",
        "\n",
        "def annotate_post_per_tag(text):\n",
        "    '''\n",
        "    Applies an annotation decision, based on pre-specified prompt 'prompt', to a given text 'text'; provides rationale and explanation.\n",
        "    '''\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "                                                  model = 'gpt-4o', ### https://platform.openai.com/docs/models\n",
        "                                                  temperature = 0.2,\n",
        "                                                  messages = [\n",
        "                                                              {\n",
        "                                                               'role': 'system',\n",
        "                                                               'content': f'{asp_prompt}{val_prompt}' ### double up prompts?\n",
        "                                                               },\n",
        "                                                              {\n",
        "                                                               'role': 'user',\n",
        "                                                               'content': f'{text}'\n",
        "                                                               },\n",
        "                                                            ]\n",
        "                                                  )\n",
        "        result = ' '\n",
        "        for choice in response.choices:\n",
        "            result += choice.message.content\n",
        "        print(f'{text}: {result}')\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f'Exception: {e}')\n",
        "        return 'error'"
      ],
      "metadata": {
        "id": "XVHvbbWf4fvH"
      },
      "id": "XVHvbbWf4fvH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**annotate_post_per_tag**"
      ],
      "metadata": {
        "id": "X6w2WRZQbajN"
      },
      "id": "X6w2WRZQbajN"
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "All my life I wished I could be a champion snowboarder, but my injuries as a child ruined that dream.\n",
        "Because I am medicated and rely on a walker to navigate only short distances, my athletic career can\n",
        "never return. I feel hopeless and stunted and passed by, and like a burden to my family.\n",
        "\n",
        "They maintain strict conservative ideals and are very traditional. I'm more forward-looking and accepting,\n",
        "and for this too they make me feel like an outcast.\n",
        "'''\n",
        "annotate_post_per_tag(text)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lUAFePwZI8pR"
      },
      "id": "lUAFePwZI8pR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "I am a sick man.... I am a spiteful man. I am an unattractive man. I believe my liver is diseased.\n",
        "However, I know nothing at all about my disease, and do not know for certain what ails me.\n",
        "I dont consult a doctor for it, and never have, though I have a respect for medicine and doctors.\n",
        "Besides, I am extremely superstitious, sufficiently so to respect medicine, anyway (I am well-educated\n",
        "enough not to be superstitious, but I am superstitious). No, I refuse to consult a doctor from spite.\n",
        "That you probably will not understand. Well, I understand it, though. Of course, I cant explain who\n",
        "it is precisely that I am mortifying in this case by my spite: I am perfectly well aware that I cannot\n",
        "pay out the doctors by not consulting them; I know better than anyone that by all this I am only\n",
        "injuring myself and no one else. But still, if I dont consult a doctor it is from spite. My liver is\n",
        "bad, welllet it get worse!\n",
        "'''\n",
        "annotate_post_per_tag(text)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mlm5NSfBRbKf"
      },
      "id": "mlm5NSfBRbKf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**annotate_dataframe_per_tag**"
      ],
      "metadata": {
        "id": "VPGKJ05Hbg27"
      },
      "id": "VPGKJ05Hbg27"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#api_key = '<api_key>' ### project = skeen_prospectus; name = annotate\n",
        "#client = OpenAI(api_key = api_key)\n",
        "\n",
        "#def annotate_dataframe_per_tag(d):\n",
        "#    '''\n",
        "#    Applies annotate_post_per_tag to each row in dataframe 'd'.\n",
        "#    '''\n",
        "#    for index, row in d.iterrows():\n",
        "#        result = annotate_post_per_tag(row['text'])\n",
        "#        if result == 'error':\n",
        "#            continue\n",
        "\n",
        "    ### SJS 7/23: good snippet; keep for now\n",
        "\n",
        "#        asp, rationale, strain, explanation = None, None, None, None\n",
        "\n",
        "#        if '1' in result:\n",
        "#            asp = 1\n",
        "#            rationale = result.split('rationale:')[1].split('strain:')[0].strip() if 'rationale:' in result else None\n",
        "#            strain = result.split('strain:')[1].split('explanation:')[0].strip() if 'strain:' in result else None\n",
        "#        else:\n",
        "#            asp = 0\n",
        "\n",
        "#        explanation = result.split('explanation:')[1].strip() if 'explanation:' in result else None\n",
        "\n",
        "#        d.at[index, 'asp_gpt'] = asp\n",
        "#        d.at[index, 'asp_rtnl_gpt'] = rationale\n",
        "#        d.at[index, 'asp_strn_gpt'] = strain\n",
        "#        d.at[index, 'expl_gpt'] = explanation\n",
        "\n",
        "        # delay between API calls\n",
        "#        time.sleep(1)\n",
        "\n",
        "#    return d\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mdHCyQ1LboMN"
      },
      "id": "mdHCyQ1LboMN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "api_key = '<api_key>'  # project = skeen_prospectus; name = annotate\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "def annotate_post_per_tag(text):\n",
        "    '''\n",
        "    Applies an annotation decision, based on pre-specified prompt 'prompt', to a given text 'text'; provides rationale and explanation.\n",
        "    '''\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "                                                  model = 'gpt-4o', ### https://platform.openai.com/docs/models\n",
        "                                                  temperature = 0.2,\n",
        "                                                  messages = [\n",
        "                                                              {\n",
        "                                                               'role': 'system',\n",
        "                                                               'content': f'{asp_prompt}{val_prompt}' ### double up prompts?\n",
        "                                                               },\n",
        "                                                              {\n",
        "                                                               'role': 'user',\n",
        "                                                               'content': f'{text}'\n",
        "                                                               },\n",
        "                                                            ]\n",
        "                                                  )\n",
        "        result = ' '\n",
        "        for choice in response.choices:\n",
        "            result += choice.message.content\n",
        "        print(f'{text}: {result}')\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f'Exception: {e}')\n",
        "        return 'error'\n",
        "    pass\n",
        "\n",
        "def annotate_dataframe_per_tag(d):\n",
        "    '''\n",
        "    Applies annotate_post_per_tag for aspiration and value strains to each row in dataframe 'd'.\n",
        "    '''\n",
        "    for index, row in d.iterrows():\n",
        "        result = annotate_post_per_tag(row['text'])\n",
        "        if result == 'error':\n",
        "            continue\n",
        "\n",
        "        # 'asp'\n",
        "\n",
        "        asp, asp_rationale, asp_strain, asp_explanation = None, None, None, None\n",
        "\n",
        "        if 'asp_1' in result:\n",
        "            asp = 1\n",
        "            asp_rationale = result.split('asp_rationale:')[1].split('strained aspirations:')[0].strip() if 'asp_rationale:' in result else None\n",
        "            asp_strain = result.split('strained aspirations:')[1].split('asp_explanation:')[0].strip() if 'strained aspirations:' in result else None\n",
        "            asp_explanation = result.split('asp_explanation:')[1].split('val_rationale:')[0].strip() if 'asp_explanation:' in result else None\n",
        "        else:\n",
        "            asp = 0\n",
        "\n",
        "        d.at[index, 'asp_gpt'] = asp\n",
        "        d.at[index, 'asp_rtnl_gpt'] = asp_rationale\n",
        "        d.at[index, 'asp_strn_gpt'] = asp_strain\n",
        "        d.at[index, 'asp_expl_gpt'] = asp_explanation\n",
        "\n",
        "        # delay between API calls\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "        # 'val'\n",
        "\n",
        "        val, val_rationale, val_strain, val_explanation = None, None, None, None\n",
        "\n",
        "        if 'val_1' in result:\n",
        "            val = 1\n",
        "            val_rationale = result.split('val_rationale:')[1].split('strained values:')[0].strip() if 'val_rationale:' in result else None\n",
        "            val_strain = result.split('strained values:')[1].split('val_explanation:')[0].strip() if 'strained values:' in result else None\n",
        "            val_explanation = result.split('val_explanation:')[1].strip() if 'val_explanation:' in result else None\n",
        "        else:\n",
        "            val = 0\n",
        "\n",
        "        d.at[index, 'val_gpt'] = val\n",
        "        d.at[index, 'val_rtnl_gpt'] = val_rationale\n",
        "        d.at[index, 'val_strn_gpt'] = val_strain\n",
        "        d.at[index, 'val_expl_gpt'] = val_explanation\n",
        "\n",
        "        # delay between API calls\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "QZ-yxIq4sYHA"
      },
      "id": "QZ-yxIq4sYHA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/Colab/prospectus/annotation/gpt_triangulation_pilot\n",
        "\n",
        "d_test = pd.read_excel('test.xlsx')\n",
        "d_test.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i4WgaeaSnric"
      },
      "id": "i4WgaeaSnric",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_test = annotate_dataframe_per_tag(d_test)\n",
        "d_test.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EUbpC-dLn1js"
      },
      "id": "EUbpC-dLn1js",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cycle 3 LLM triangulation: pilot"
      ],
      "metadata": {
        "id": "2WTIi81yNO-e"
      },
      "id": "2WTIi81yNO-e"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/Colab/prospectus/annotation/llm_triangulation\n",
        "\n",
        "d = pd.read_excel('iaa_cycle3.xlsx')\n",
        "\n",
        "# focus on asp for pilot...\n",
        "\n",
        "    ### SJS 7/15: reset index - later\n",
        "\n",
        "d = d[[\n",
        "       'p_id',\n",
        "       'text',\n",
        "       'asp_sd',\n",
        "       'asp_ss',\n",
        "       'asp_rtnl_sd',\n",
        "       'asp_rtnl_ss',\n",
        "       ]].copy()\n",
        "\n",
        "d.shape\n",
        "d.head(3)"
      ],
      "metadata": {
        "id": "hGaeOe7KNNPG"
      },
      "id": "hGaeOe7KNNPG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# triangulate Cycle 3\n",
        "\n",
        "d = annotate_dataframe_per_tag(d)\n",
        "#print(d)\n",
        "d.head(3)\n"
      ],
      "metadata": {
        "id": "l5voB8InNNTS"
      },
      "id": "l5voB8InNNTS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.to_excel('iaa-gpt_cycle3.xlsx')"
      ],
      "metadata": {
        "id": "zNG8iFLZNNau"
      },
      "id": "zNG8iFLZNNau",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cycle 4 LLM triangulation: _asp_ and _val_"
      ],
      "metadata": {
        "id": "LJRJdAbH51Ng"
      },
      "id": "LJRJdAbH51Ng"
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "2-1HiVfrmSvK"
      },
      "id": "2-1HiVfrmSvK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "collapsed": true,
        "id": "KpFSzIot6qeZ"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/My Drive/Colab/bar_policy_suicidality/inputs/annotation\n",
        "\n",
        "d_sd = pd.read_excel('d_cycle4_sd.xlsx')\n",
        "#d_sd.dtypes\n",
        "\n",
        "#d_sd = d_sd.replace(' ', 0)\n",
        "d_sd.columns = [f'{col}_sd' for col in d_sd.columns]\n",
        "\n",
        "\n",
        "d_ss = pd.read_excel('d_cycle4_ss.xlsx')\n",
        "#d_ss.dtypes\n",
        "\n",
        "#d_ss = d_ss.replace(' ', 0)\n",
        "d_ss.columns = [f'{col}_ss' for col in d_ss.columns]\n",
        "\n",
        "\n",
        "# inspect\n",
        "\n",
        "#d_sd.head(3)\n",
        "#d_ss.head(3)\n",
        "\n",
        "# merge\n",
        "\n",
        "d = pd.merge(\n",
        "             d_sd,\n",
        "             d_ss,\n",
        "             left_index = True,\n",
        "             right_index = True,\n",
        "             )\n",
        "\n",
        "targets = [\n",
        "           'asp_sd', 'asp_ss',\n",
        "           'dep_sd', 'dep_ss',\n",
        "           'val_sd', 'val_ss',\n",
        "           'prg_sd', 'prg_ss',\n",
        "           'tgd_sd', 'tgd_ss',\n",
        "           'age_sd', 'age_ss',\n",
        "           'race_sd', 'race_ss',\n",
        "           'dbty_sd', 'dbty_ss',\n",
        "           'insb_sd', 'insb_ss',\n",
        "            ]\n",
        "\n",
        "#d = d[targets].copy()\n",
        "\n",
        "d[targets] = d[targets].apply(\n",
        "                              pd.to_numeric,\n",
        "                              errors = 'coerce',\n",
        "                              )\n",
        "\n",
        "d = d.fillna(0)\n",
        "d = d.replace(' ', 0)\n",
        "#d = d.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "d = d[[\n",
        "        #targets,\n",
        "        'p_id_sd', 'p_id_ss', ### sense-check for bad merge\n",
        "        'text_sd',\n",
        "        'asp_sd', 'asp_ss',\n",
        "        'asp_rtnl_sd', 'asp_rtnl_ss',\n",
        "        'asp_strn_sd', 'asp_strn_ss', ### added _strn 'name the aspiration'\n",
        "        'dep_sd', 'dep_ss',\n",
        "        'dep_rtnl_sd', 'dep_rtnl_ss',\n",
        "        'val_sd', 'val_ss',\n",
        "        'val_rtnl_sd', 'val_rtnl_ss',\n",
        "        'val_strn_sd', 'val_strn_ss', ### added _strn 'name the value'\n",
        "        'prg_sd', 'prg_ss',\n",
        "        'tgd_sd', 'tgd_ss',\n",
        "        'age_sd', 'age_ss',\n",
        "        'race_sd', 'race_ss',\n",
        "        'dbty_sd', 'dbty_ss',\n",
        "        'insb_sd', 'insb_ss',\n",
        "        ]].copy()\n",
        "\n",
        "d.rename(\n",
        "           columns = {\n",
        "                      'p_id_sd': 'p_id',\n",
        "                      'text_sd': 'text',\n",
        "                      }, inplace = True,\n",
        "          )\n",
        "\n",
        "#d.to_excel('iaa_inspect.xlsx')\n",
        "\n",
        "# drop insb = 1 (either annotator)\n",
        "\n",
        "#d = d[(d['insb_sd'] != 1) & (d['insb_ss'] != 1)]\n",
        "\n",
        "# target = 0 for insb = 1 (either annotator)\n",
        "\n",
        "# check: 'insb_sd' or 'insb_ss' is 1\n",
        "\n",
        "condition = (d['insb_sd'] == 1) | (d['insb_ss'] == 1)\n",
        "\n",
        "# 'asp', 'dep', and 'val' = 0 where 'insb' = True\n",
        "\n",
        "d.loc[condition, ['asp', 'val', 'dep']] = 0\n",
        "\n",
        "\n",
        "'n valid'\n",
        "d.shape\n",
        "\n",
        "# to numpy\n",
        "\n",
        "#for target in targets:\n",
        "#    target = d[target].to_numpy()\n",
        "\n",
        "# kappa Fx\n",
        "\n",
        "def calculate_kappa(d, col_sd, col_ss):\n",
        "    return cohen_kappa_score(d[col_sd], d[col_ss])\n",
        "\n",
        "column_pairs = [\n",
        "                ('asp_sd', 'asp_ss'),\n",
        "                ('dep_sd', 'dep_ss'),\n",
        "                ('val_sd', 'val_ss'),\n",
        "                #('prg_sd', 'prg_ss'),\n",
        "                #('tgd_sd', 'tgd_ss'),\n",
        "                #('age_sd', 'age_ss'),\n",
        "                #('race_sd', 'race_ss'),\n",
        "                #('dbty_sd', 'dbty_ss'),\n",
        "                ]\n",
        "\n",
        "kappa_results = {}\n",
        "\n",
        "for col_sd, col_ss in column_pairs:\n",
        "    kappa = calculate_kappa(d, col_sd, col_ss)\n",
        "    kappa_results[f'{col_sd} and {col_ss}'] = kappa\n",
        "\n",
        "for pair, kappa in kappa_results.items():\n",
        "    print(f\"Cohen's Kappa for {pair}: {kappa:.2f}\")\n",
        "\n",
        "\n",
        "# disagreement Fx\n",
        "\n",
        "def d_disagree(row):\n",
        "    return 1 if row[0] != row[1] else 0\n",
        "\n",
        "sts_pairs = [('asp_sd', 'asp_ss', 'asp_dis'),\n",
        "             ('dep_sd', 'dep_ss', 'dep_dis'),\n",
        "             ('val_sd', 'val_ss', 'val_dis')]\n",
        "\n",
        "for col1, col2, dis_col in sts_pairs:\n",
        "    d[dis_col] = d[[col1, col2]].apply(d_disagree, axis = 1)\n",
        "\n",
        "#d.to_excel('iaa_cycle3.xlsx')\n",
        "#d.dtypes\n",
        "#d.head(3)"
      ],
      "id": "KpFSzIot6qeZ"
    },
    {
      "cell_type": "code",
      "source": [
        "#d.shape\n",
        "#d.dtypes\n",
        "#d.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kqREk8kIBk0l"
      },
      "id": "kqREk8kIBk0l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df for SJS-SD disagreements\n",
        "\n",
        "d_dis = d[(d['asp_dis'] == 1) | (d['val_dis'] == 1)]\n",
        "d_dis.shape\n",
        "\n",
        "# drop disagreements fr orig df\n",
        "\n",
        "d_agr = d[~((d['asp_dis'] == 1) | (d['val_dis'] == 1))]\n",
        "d_agr.shape\n",
        "\n",
        "# GPT-4o - asp\n",
        "\n",
        "d_dis = annotate_dataframe_per_tag(d_dis)\n",
        "\n",
        "# append d_dis to d_agr\n",
        "\n",
        "d_iaa_gpt_cycle4 = pd.concat(\n",
        "                             [\n",
        "                              d_dis,\n",
        "                              d_agr,\n",
        "                              ], ignore_index = True,\n",
        "                             )\n",
        "\n",
        "# prioritize GPT-4o-annotated rows for human inspection\n",
        "\n",
        "d_iaa_gpt_cycle4 = d_iaa_gpt_cycle4.sort_values(\n",
        "                                                by = [\n",
        "                                                      'asp_dis',\n",
        "                                                      'val_dis',\n",
        "                                                      ], ascending = False\n",
        "                                                ).reset_index(drop = True)\n",
        "\n",
        "d_iaa_gpt_cycle4.head(3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3i3BRyW35tUr"
      },
      "id": "3i3BRyW35tUr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort cols for human readability + add 'notes'\n",
        "\n",
        "d_iaa_gpt_cycle4['notes_for_asp'] = ' '\n",
        "d_iaa_gpt_cycle4['notes_for_val'] = ' '\n",
        "\n",
        "d_iaa_gpt_cycle4 = d_iaa_gpt_cycle4[[\n",
        "                                     'text',\n",
        "                                     'asp_sd',\n",
        "                                     'asp_ss',\n",
        "                                     'asp_gpt',\n",
        "                                     'asp_rtnl_sd',\n",
        "                                     'asp_rtnl_ss',\n",
        "                                     'asp_rtnl_gpt',\n",
        "                                     'asp_strn_sd',\n",
        "                                     'asp_strn_ss',\n",
        "                                     'asp_strn_gpt',\n",
        "                                     'asp_expl_gpt',\n",
        "                                     'asp_dis',\n",
        "                                     'notes_for_asp',\n",
        "\n",
        "                                     'text',\n",
        "                                     'val_sd',\n",
        "                                     'val_ss',\n",
        "                                     'val_gpt',\n",
        "                                     'val_rtnl_sd',\n",
        "                                     'val_rtnl_ss',\n",
        "                                     'val_rtnl_gpt',\n",
        "                                     'val_strn_sd',\n",
        "                                     'val_strn_ss',\n",
        "                                     'val_strn_gpt',\n",
        "                                     'val_expl_gpt',\n",
        "                                     'val_dis',\n",
        "                                     'notes_for_val',\n",
        "                                     ]].copy()\n",
        "\n",
        "d_iaa_gpt_cycle4.shape\n",
        "d_iaa_gpt_cycle4.head(3)"
      ],
      "metadata": {
        "id": "muXsTzg2S9l8"
      },
      "id": "muXsTzg2S9l8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_iaa_gpt_cycle4.to_excel('d_iaa_gpt_cycle4.xlsx')"
      ],
      "metadata": {
        "id": "iKv8mk4q5tYM"
      },
      "id": "iKv8mk4q5tYM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cycle 4: Post-LLM triangulation: _asp_ and _val_"
      ],
      "metadata": {
        "id": "WrTcLugafdLp"
      },
      "id": "WrTcLugafdLp"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab/dissertation/annotation\n",
        "\n",
        "d = pd.read_excel('d_iaa_gpt_cycle4_sd-ss.xlsx')\n",
        "\n",
        "def calculate_kappa(d, col_sd, col_ss):\n",
        "    return cohen_kappa_score(d[col_sd], d[col_ss])\n",
        "\n",
        "# cols: SJS-SD\n",
        "\n",
        "column_pairs = [\n",
        "                ('asp_sd', 'asp_ss'),\n",
        "                ('val_sd', 'val_ss'),\n",
        "                ]\n",
        "\n",
        "kappa_results = {}\n",
        "\n",
        "for col_sd, col_ss in column_pairs:\n",
        "    kappa = calculate_kappa(d, col_sd, col_ss)\n",
        "    kappa_results[f'{col_sd} and {col_ss}'] = kappa\n",
        "\n",
        "for pair, kappa in kappa_results.items():\n",
        "    print(f\"Cohen's Kappa for {pair}: {kappa:.2f}\")\n"
      ],
      "metadata": {
        "id": "AttvaVQEfcQW"
      },
      "id": "AttvaVQEfcQW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viz"
      ],
      "metadata": {
        "id": "zFnfNY485dGK"
      },
      "id": "zFnfNY485dGK"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab/bar_policy_suicidality/outputs/tables\n",
        "\n",
        "d_v = pd.read_excel('d_cycle_kappas.xlsx')"
      ],
      "metadata": {
        "id": "0NrhZckF5cYo"
      },
      "id": "0NrhZckF5cYo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%cd .../figures\n",
        "\n",
        "sns.set(style = 'whitegrid')\n",
        "\n",
        "# custom x-axis labels\n",
        "\n",
        "custom_labels = [\n",
        "                 'cycle 1',\n",
        "                 'cycle 2',\n",
        "                 'cycle 3',\n",
        "                 'pre-GTP: cycle 4',\n",
        "                 'post-GPT: cycle 4',\n",
        "                 ]\n",
        "\n",
        "# plot\n",
        "\n",
        "plt.figure(figsize = (\n",
        "                      8,\n",
        "                      6,\n",
        "                      )\n",
        "          )\n",
        "\n",
        "plt.plot(\n",
        "         d_v['cycle'],\n",
        "         d_v['asp_cohens_k'],\n",
        "         label = \"asp\",\n",
        "         marker = 's',\n",
        "         alpha = 0.6,\n",
        "         color = 'hotpink',\n",
        "         )\n",
        "\n",
        "plt.plot(\n",
        "         d_v['cycle'],\n",
        "         d_v['dep_cohens_k'],\n",
        "         label = \"dep\",\n",
        "         marker = 's',\n",
        "         alpha = 0.6,\n",
        "         color = 'tomato',\n",
        "         )\n",
        "\n",
        "plt.plot(\n",
        "         d_v['cycle'],\n",
        "         d_v['val_cohens_k'],\n",
        "         label = \"val\",\n",
        "         marker = 's',\n",
        "         alpha = 0.6,\n",
        "         color = 'mediumorchid',\n",
        "         )\n",
        "\n",
        "# labels, title\n",
        "\n",
        "#plt.xlabel('Cycle')\n",
        "plt.ylabel(\"Cohen's $\\kappa$\")\n",
        "#plt.title(\"Cohen's $\\kappa$ Value per Cycle for ASP, DEP, and VAL\")\n",
        "\n",
        "# custom x-axis labels, 45-degree angle\n",
        "\n",
        "plt.xticks(\n",
        "           ticks = d_v['cycle'],\n",
        "           labels=custom_labels,\n",
        "           rotation = 45,\n",
        "           )\n",
        "\n",
        "\n",
        "\n",
        "# horizontal gridlines\n",
        "\n",
        "plt.grid(axis='x')\n",
        "\n",
        "# set line at 0.7 threshold\n",
        "\n",
        "plt.axhline(\n",
        "            y = 0.7,\n",
        "            color = 'red',\n",
        "            linewidth = 0.6,\n",
        "            linestyle = '--',\n",
        "            )\n",
        "\n",
        "# x-axis at 0\n",
        "\n",
        "plt.ylim(\n",
        "         0,\n",
        "         None,\n",
        "         )\n",
        "\n",
        "# legend\n",
        "\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3, frameon=False)\n",
        "\n",
        "# x-axis ticks\n",
        "\n",
        "plt.gca().tick_params(axis='x', which='both', direction='in', length=5)  # Adds ticks to the x-axis labels\n",
        "\n",
        "# optimized markers\n",
        "\n",
        "#x0 = [2, 5, 5]\n",
        "#y0 = [0.72, 0.96, 0.97]\n",
        "#plt.plot(x0, y0, \"s\", markersize = 7, color = 'red')\n",
        "\n",
        "#for a,b in zip(x0, y0):\n",
        "#    plt.text(a, b, str(b),fontsize=9, ha='right',va='top')\n",
        "\n",
        "sns.despine(\n",
        "            left = True,\n",
        "            )\n",
        "\n",
        "# tight layout\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# save\n",
        "\n",
        "plt.savefig('cycle_kappa_line.png')\n",
        "\n",
        "# display\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dqSXfMO26Y3a"
      },
      "id": "dqSXfMO26Y3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6336ff2d-94e0-4d83-9c34-af0260603a5f",
      "metadata": {
        "id": "6336ff2d-94e0-4d83-9c34-af0260603a5f"
      },
      "source": [
        "> End of bar_sample_annotate_iaa.ipynb"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}